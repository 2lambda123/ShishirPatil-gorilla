<!DOCTYPE html>
<html>
<head>
    
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NRZJLJCSH6"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-NRZJLJCSH6');
    </script>


    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <title>Gorilla</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro">
    <link rel="stylesheet" href="assets/css/Highlight-Clean.css">
    <link rel="stylesheet" href="assets/css/styles.css">
    <link rel="stylesheet" href="assets/css/Team-Clean.css">
</head>

<body>
       <!-- Navigation Bar -->
    <div class="navbar" style="position: absolute; top: 0; right: 20px; padding: 10px; z-index: 100;font-size: 18px;">
        <a href="index.html">Home </a>&nbsp;&nbsp;&nbsp;     
        <a href=""> Blog</a>
    </div>

    <!-- Add this inside the "highlight-clean-blog" div -->
<div class="box-index">
    <h3>Blogs</h3>
    <ul>
        <li><a href="blogs/blog_post_1.html">Introduction to Gorilla LLM</a></li>
        <li><a href="blogs/blog_post_2.html">Retrieval Aware Training (RAT)</a></li>
        <li><a href="blogs/blog_post_3.html">How to Measure Hallucination?</a></li>
        <!-- Add more entries as needed -->
    </ul>
</div>

<div class="highlight-clean-blog" style="padding-bottom: 0px;">
    <h1 class="text-center" style="padding-bottom: 0px;"> ü¶ç Gorilla: Large Language Model Connected with Massive APIs</h1>
    <!-- Rest of your content -->
</div>

    <div class="highlight-clean-blog" style="padding-bottom: 10px;">        
        <div class="blog-container">
            <div class="blog-post">
                <p>
                    Since the initial release of Gorilla LLM on May 25, 2023, we're incredibly grateful for your overwhelming response. The Gorilla project is loved by developers worldwide. Through our integrations with an evergrowing set of API calls, we've close to serving ~500k user requests all from our small node at UC Berkeley. Some of you have gone ahead to train your own Gorilla's for your custom use-cases, and we love to see the community grow.
                    
                    To enhance the support for individual developers and enterprises looking to adopt, or train their own Gorilla models, we're collaborating with our colleagues to launch a comprehensive blog series. In this series will delve deeper into the intricacies of Gorilla and outline our strategic vision and roadmap for the future.
                </p>
                <br>

                <h2 class="blog-title">Introduction to Gorilla LLM</h2>
                <div class="author-date">
                    <p class="author"> <a href="https://www.lisabdunlap.com/">Lisa Dunlap</a>  </p>
                    <p class="date">Oct 3, 2023</p>
                </div>      
                <img src="assets/img/blog_post_1_teaser.gif" alt="Gorilla introductory image" style="width: 100%;">
                <div class="preview">
                    <p> 
                        Gorilla is designed to connect large language models (LLMs) with a wide range of tools, services, and applications exposed through APIs. Imagine if ChatGPT could interact with thousands of services ranging from Instagram and Doordash to tools like Google Calendar and Stripe to help you accomplish tasks.  You could ask to book a meeting for your collaborators, order their favorite foods, and pay for it. This may be how we interact with computers and even the web in the future.
                    </p>
                    
                    <p>
                        Gorilla is an LLM that we train using a concept we call - retriever-aware training, that can pick the right API to perform a task, that a user can specify in natural language. We also introduce an Abstract Syntax Tree (AST) based sub-tree algorithm, which for the first time can measure hallucination of LLMs! 
                    </p>


                </div>
                <a class="continue-link" href="blogs/blog_post_1.html">Continue Reading ...</a>
                <hr class="post-separator">
            </div>
        
            <!-- Blog Post 2 -->
            <div class="blog-post">
                <h2 class="blog-title">Blog Post Title 2</h2>
                <div class="author-date">
                    <p class="author"> <a href="https://people.eecs.berkeley.edu/~wong.justin/"> Justin Wong </a>  </p>
                    <p class="date">Oct 3, 2023</p>
                </div>
                <img src="assets/img/blog_post_2_image.jpg" alt="Blog Post 2 Image">
                <div class="preview">
                    <p>Diffusion models have recently emerged as the de facto standard for generating complex, high-dimensional outputs. You may know them for their ability to produce stunning AI art and hyper-realistic synthetic images, but they have also found success in other applications such as drug design and continuous control. The key idea behind diffusion models is to iteratively transform random noise into a sample, such as an image or protein structure. This is typically motivated as a maximum likelihood estimation problem, where the model is trained to generate samples that match the training data as closely as possible.</p>

                    <p>However, most use cases of diffusion models are not directly concerned with matching the training data, but instead with a downstream objective. We don‚Äôt just want an image that looks like existing images, but one that has a specific type of appearance; we don‚Äôt just want a drug molecule that is physically plausible, but one that is as effective as possible. In this post, we show how diffusion models can be trained on these downstream objectives directly using reinforcement learning (RL). To do this, we finetune Stable Diffusion on a variety of objectives, including image compressibility, human-perceived aesthetic quality, and prompt-image alignment. The last of these objectives uses feedback from a large vision-language model to improve the model‚Äôs performance on unusual prompts, demonstrating how powerful AI models can be used to improve each other without any humans in the loop.</p>
                </div>
                <a class="continue-link" href="blogs/blog_post_2.html">Continue</a>
                <hr class="post-separator">
            </div>
            </div>
    </div>

<style>
    body {
        font-family: 'Source Sans Pro', sans-serif;
        margin: 0;
        padding: 0;
        background: white;
        justify-content: center;
        align-items: center;
    }
    .blog-container {
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
    }
    .blog-post {
        margin: 20px;
        padding: 20px;
        max-width: 1000px; 
        justify-content: center;
    }
    .blog-post img {
        display: block;
        margin: 0 auto;
    }
    .blog-title{
        color: #055ada;
        text-align: center;
    }

    .author-date {
            display: flex;
            margin-bottom: 0px;
            justify-content: center; 
    }
    .author {
            font-size: 16px;
            color: #1E90FF;
            margin-right: 20px;
    }

    .date {
        font-size: 16px;
        color: #7e8790;
    }

    .continue-link {
        display: block;
        margin-top: 10px; 
        text-align: left;
    }

    .highlight-clean-blog {
        color: #313437;
        background-color: #fff;
        padding: 50px 0;
    }

    .post-separator {
        border: 0.5px solid #e8e8e8; 
        margin: 20px 0; 
    }


    .preview {
        text-align: justify; 
        text-justify: inter-word; 
    }

  
    .box-index {
    position: fixed;
    top: 50%; 
    left: 20px; 
    transform: translateY(-50%);
    background-color: #f9f9f9;
    padding: 20px;
    border-radius: 8px;
    box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
    max-width: 250px;
    }

    .box-index h3 {
    font-size: 1.2em;
    margin-bottom: 10px;
    }

    .box-index ul {
    list-style-type: disc;
    padding: 0;
    }

    .box-index ul li {
    margin-bottom: 10px;
    }

    .box-index ul li a {
    text-decoration: none;
    color: #333;
    }

    .box-index ul li a:hover {
    color: #1E90FF;
    }


    @media screen and (max-width: 768px) {
    .blog-post {
        padding: 10px; /* Adjust spacing for smaller screens */
    }
    .blog-post img {
        max-width: 80%; /* Reduce image size for smaller screens */
    }

    .box-index {
        display: none; /* Hide the index on smaller screens */
    }
}

</style>
</body>

</html>