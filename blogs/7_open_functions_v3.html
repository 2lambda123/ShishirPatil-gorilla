<!DOCTYPE html>
<html>
<head>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NRZJLJCSH6"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-NRZJLJCSH6');
    </script>


    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <title>Introduction to Gorilla LLM</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro">
    <link rel="stylesheet" href="assets/css/Highlight-Clean.css">
    <link rel="stylesheet" href="assets/css/styles.css">
    <link rel="stylesheet" href="assets/css/Team-Clean.css">
</head>

<body>
    <!-- Navigation Bar -->
    <div class="navbar" style="position: absolute; top: 0; right: 20px; padding: 10px; z-index: 100;font-size: 18px;">
        <a href="../index.html">Home </a>&nbsp;&nbsp;&nbsp;     
        <a href="../blog.html"> Blog</a>
    </div>

    <div class="highlight-clean-blog" style="padding-bottom: 10px;">
        <h1 class="text-center" style="padding-bottom: 10px;"> ü¶ç Gorilla: Large Language Model Connected with Massive APIs</h1>

        <div class="blog-container">
            <div class="blog-post">
                <h2 class="blog-title">Gorilla OpenFunctions v3</h2>
                <div class="col-md-12">
                    <h4 class="text-center" style="margin: 0px;">
                         <p></p>
                         <a class="author" href="https://fanjia-yan.github.io/">Fanjia Yan<sup>*</sup></a>
                         <a class="author" href="https://huanzhimao.com/">Huanzhi Mao<sup>*</sup></a>
                         <a class="author" href="https://charliejcj.github.io/">Charlie Cheng-Jie<sup>*</sup></a>
                         <a class="author" href="https://tianjunz.github.io">Tianjun Zhang</a>
                         <a class="author" href="https://people.eecs.berkeley.edu/~shishirpatil/">Shishir G. Patil</a>
                         <a class="author" href="https://people.eecs.berkeley.edu/~jegonzal/">Joseph E. Gonzalez</a>
                         <a class="author" href="https://people.eecs.berkeley.edu/~istoica">Ion Stoica</a>
                         <p></p>
                    </h4>
                </div>
                    <img src="../assets/img/blog_post_7_demo.gif" alt="Gorilla introductory image" style="width: 100%;">
                    <p width="80%" style="text-align:center; margin-left:10%; margin-right:10%; padding-bottom: -10px">
                        <i style="font-size: 0.9em;">
                            Gorilla OpenFunctions-v2! SoTA for open-source models. On-par with commercial models. 
                        </i>
                    </p>

                <div class="preview">
                    <p>
                        With the latest iteration of Gorilla OpenFunctions, version 2, we are delighted to mark significant advancements in function calling for LLMs within the open-source community. As a direct substitute for its predecessor, Gorilla OpenFunctions-v2 retains its open-source ethos while introducing exciting enhancements. These include support for multiple programming languages such as Python, Java, JavaScript and REST API - the first among open-source and closed-source models, alongside the ability to handle multiple and parallel function calls, and the ability to determine function relevance. This update cements gorilla-openfunctions-v2's position at the forefront of function calling capabilities among LLMs. Moreover, the drop-in-replacement allows for seamless integration of OpenFunctions into a diverse range of applications, from social media platforms like Instagram to delivery services like Doordash, as well as utility tools including Google Calendar and Stripe.
                    </p>
                </div>



                <!-- 5 New Features -->
                <p style="text-align: center; margin-bottom: 0">
                    <img src="../assets/img/blog_post_7_open_function_v2_features.png" alt="New Features in Gorilla LLMs" width="100%">
                    <br>
                </p>
                <p width="80%" style="text-align:center; margin-left:10%; margin-right:10%; padding-bottom: -10px">
                    <i style="font-size: 0.9em;">
                        The five new exciting features we are happy to launch with OpenFunctions-v2 are:
                    </i>
                </p>

                <h4 id="whats_new"> See What's New!! &#128640 </h4>
                <div class="body">
                    <p>
                        <ul>
                            <li><strong>More Data Types:</strong> Gorilla Open Functions v2 can now support diverse languages with expanded support for argument types in function calls. This includes <code>[string, number, boolean, list, tuple, dict, any]</code> for Python, <code>[string, number, boolean, list, tuple, dict, any]</code> for Java and <code>[string, number, boolean, dict, bigint, array, date, any]</code> for Javascript. For reference, OpenAI and many others only support JSON schema, i.e., <code>[string, number, integer, object, array, and boolean]</code>. Native support for these types means, you can now plug-and-play openfunctions-v2 without having to weave through string literals.</li>
                            <li><strong>Parallel & Multiple Functions:</strong> Support for Parallel and Multiple Functions. Multiple functions refers to the scenario where the user can input multiple functions when they are not sure which exact function is best to service the prompt. In this scenario, the Gorilla model picks one or more (or none) of the functions provided to respond to the user's requests. In parallel functions, the user's prompt could be serviced by multiple calls to the same function. Gorilla not only supports both of these, but the benefits stack one-on-top of the other! </li>
                            <li><strong>Function Relevance Detection:</strong> Reduce hallucinations in scenarios when no function, or even no relevant function is provided. Gorilla openfunctions v2 can now automatically detect whether the functions provided to the model can address the user's prompt. Recognizing this, the LLM raises an ‚ÄúError‚Äù message to the user providing them with additional information.</li>
                            <li><strong>Enhanced Capabilities for Restful APIs:</strong> Enhance ability to format RESTful API calls. RESTful APIs are a common phenomenon within the web powering many popular software services including Slack, PayPal, etc. Our model is specially trained to handle RESTful API calls with good quality.</li>
                        </ul>
                    </p>
                    <p>
                        Quick Links:
                        <ul>
                            <li>How well to other function-calling models perform: <a href="https://gorilla.cs.berkeley.edu/leaderboard.html">Berkeley Function Calling Leaderboard</a></li>
                            <li>Play with the model online: <a href="https://gorilla.cs.berkeley.edu/leaderboard.html">Gorilla OpenFunctions-v2 web-demo</a></li>
                            <li>Check out the project: <a href="https://github.com/ShishirPatil/gorilla/tree/main/openfunctions">GitHub</a></li>
                            <li>Model (7B) on HuggingFace: <a href="https://huggingface.co/gorilla-llm/gorilla-openfunctions-v2">gorilla-llm/gorilla-openfunctions-v2</a></li>
                        </ul>
                    </p>
                </div>

                <!-- Measuring Hallucination  -->
                <p style="text-align: center; margin-bottom: 0">
                    <img src="../assets/img/blog_post_1_inference.jpg" alt="Gorilla can be used in zero-shot and with retrievers" width="95%">
                    <br>
                </p>
                <p width="80%" style="text-align:center; margin-left:10%; margin-right:10%; padding-bottom: -10px">
                    <i style="font-size: 0.9em;">
                        Gorilla, can be used for inference in two modes: <em>zero-shot</em> and <em>with retrieval</em>. In zero-shot, the prompt is directly fed to the Gorilla LLM model. 
                        In retrieval mode, the retriever first retrieves the most up-to-date API documentation stored in APIZoo. 
                    </i>
                </p>

                <h4 id="how_to_use_open_functions">Integrating OpenFunctions-v2 in your App üî®</h4>
                <div class="body">
                    <p> Using Gorilla OpenFunctions-v2 is straightforward:
                        <ol>
                            <li>To help with quick prototyping, we provide a hosted Gorilla Openfunctions-v2 model for inference. Or you can run it locally, or self-host it by accessing the model from <a href="https://huggingface.co/gorilla-llm/gorilla-openfunctions-v2">HuggingFace</a>. The example below, demonstrates how to invoke the hosted gorilla openfunctions v2 model:</li>
                            <!-- <code>
import openai

def get_gorilla_response(prompt="", model="gorilla-openfunctions-v2", functions=[]):
    openai.api_key = "EMPTY"  # Hosted for free with <span style="color:#ff0000;">‚ù§Ô∏è</span> from UC Berkeley
    openai.api_base = "http://luigi.millennium.berkeley.edu:8000/v1"
    try:
    completion = openai.ChatCompletion.create(
        model="gorilla-openfunctions-v2",
        temperature=0.0,
        messages=[{"role": "user", "content": prompt}],
        functions=functions,
    )
    # completion.choices[0].message.content, string format of the function call 
    # completion.choices[0].message.functionsl, Json format of the function call
    return completion.choices[0]
                            </code> -->
                        


                    </p>
                </div>

                <!-- Gorilla side by side comparison -->
                <p style="text-align: center; margin-bottom: 0">
                    <img src="../assets/img/blog_post_1_result.png" alt="How well does Gorilla perform" width="65%">
                    <br>
                </p>
                <p width="80%" style="text-align:center; margin-left:10%; margin-right:10%; padding-bottom: -10px">
                    <i style="font-size: 0.9em;">
                        Examples of API calls. In this example, for the given prompt GPT-4 presents a model that doesn't exist, and Claude picks an incorrect library. In contrast, our Gorilla model can identify the task correctly and suggest a fully-qualified API call.
                    </i>
                </p>

                <h4 id="hallucination">Reality Bytes: When LLMs See Things That Aren't There</h4>
                <div class="body">
                    <p>
                        Hallucination is the center of discussions for all things LLMs. In the context of API generation, hallucination can be defined as the model generating API calls that do not exist. An LLM generation can be in-accurate or it could be hallucinated. One does not mean the other. For example, if the user asks for a classifier for medical images, if the model generates a Stripe API call for a image classifier - it is hallucination, since it doesn't exist! On the other hand, if the model recommends to use the Stripe API for checking your balance, it is an incorrect usage of the API, but atleast not made up (noh-hallucinated). In our blog <a href=""></a> we describe Gorilla's innovative approach of using Abstract Syntax Trees (ASTs) to measure hallucination of the generated API calls. 
                        Though not generalizable to all tasks, to the best of our knowledge, Gorilla is the first to measure and quantify hallucination for LLM generations! 

                    </p>
                </div>

                <h4 id="gorilla-hallucination">Gorilla Hallucinations</h4>
                <div class="body">
                    <p>
                        Good retrievers reduce hallucinations. The outlined AST subtree matching method highlights the importance of quality retrieval in reducing hallucinations. We evaluate Gorilla on three retrieval settings: 1) BM-25, a classic keyword retriever, 2) GPT-Index, a nearest neighbor search over gpt document embeddings, and 3) Oracle, ground truth. Each retriever appends the documentation of one API call to the context. With the improvement in retrieval accuracy from BM-25 to GPT-index we see Gorilla virtually eliminate hallucinations. GPT-4 also shows strong benefit from retriever quality leading to a 91% reduction to hallucination. Remarkably, GPT-4 benefits more from retrieval than Claude suggesting models can be optimized to make better use of retrieved documentation! Learn more about our retriever-augmented generation here.
                    </p>
                </div>

                <h4 id="Takeaways">Takeaways</h4>
                <div class="body">
                    <p>
                        Language models just like humans will hallucinate and non-maliciously make false statements. Though our focus is on LLM APIs, to the best of our knowledge, Gorilla is the first to measure and quantify hallucination for LLM generations! 

                        ‚ÄúThough our focus is on LLM APIs, to the best of our knowledge, Gorilla is the first to measure and quantify hallucination for LLM generations! ‚Äù

                        These are some takeaways on measuring hallucinations:
                        <ul>
                            <li>Use ASTs to measure API hallucination. For LLM APIs, we introduce a novel approach to check for hallucinations using subtree matching of Abstract Syntax Trees (AST).Retrievers reduce hallucinations. We find that improving the retriever reduces hallucinations!</li>

                            <li>The first step in solving a problem is recognizing there is one. We are excited by the potential of automatically fixing and self-healing when API calls are hallucinated. Just as you would ask if grandmother meant to suggest cutting the strawberries, we envision future language model powered API calls will ask targeted clarifying questions.</li>
                        </ul> 
                    </p>
                </div>
            </div>
        </div>
    </div>

    <style>
        /* Styling for <code> blocks */
        code {
            display: block; /* Makes <code> element block-level for easier styling */
            white-space: pre-wrap; /* Allows content to wrap */
            overflow-x: auto; /* Enables horizontal scrolling if needed */
            max-width: 100%; /* Prevents the element from extending beyond its parent */
            box-sizing: border-box; /* Ensures padding is included in total width */
            background-color: #f4f4f4; /* Light gray background */
            padding: 10px; /* Adds space around the content */
            border-radius: 5px; /* Rounded corners for aesthetics */
            font-size: 16px; /* Default font size */
            margin-bottom: 20px; /* Adds space below the code block */
        }

        body {
            font-family: 'Source Sans Pro', sans-serif;
            margin: 0;
            padding: 0;
            background: white;
            justify-content: center;
            align-items: center;
        }
        .blog-container {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }
        .blog-post {
            margin: 20px;
            padding: 20px;
            max-width: 1000px; 
            justify-content: center;
        }
        .blog-post img {
            display: block;
            margin: 0 auto;
        }
        .blog-title{
            color: #055ada;
            text-align: center;
        }

        .author-date {
                display: inline-flex;
                margin-bottom: 0px;
                justify-content: center; 
        }
        .author {
                font-size: 16px;
                color: #1E90FF;
                margin-right: 20px;
        }

        .date {
            font-size: 16px;
            color: #7e8790;
        }

        .preview {
            text-align: justify; 
            text-justify: inter-word; 
        }

        .highlight-clean-blog {
            color: #313437;
            background-color: #fff;
            padding: 50px 0;
        }

        .box-index {
        position: fixed;
        top: 50%; 
        left: 0px; 
        transform: translateY(-50%);
        background-color: #f9f9f9;
        padding: 20px;
        border-radius: 8px;
        box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        max-width: 150px;
        }

        .box-index h3 {
        font-size: 1.2em;
        margin-bottom: 10px;
        }

        .box-index ul {
        list-style-type: disc;
        padding: 0;
        }

        .box-index ul li {
        margin-bottom: 10px;
        }

        .box-index ul li a {
        text-decoration: none;
        color: #333;
        }

        .box-index ul li a:hover {
        color: #1E90FF;
        }

        .more-blogs .sub-menu {
            display: none;
        }

        .more-blogs .sub-menu.expanded {
            display: block;
            max-height: 200px; /* Adjust the max height as needed */
            overflow-y: auto;
        }

        .more-blogs .sub-menu li {
            padding: 10px;
            border-bottom: 1px solid #ccc;
        }

        .more-blogs .sub-menu li:last-child {
            border-bottom: none;
        }

        .more-blogs .caret {
            transition: transform 0.3s ease-in-out;
            display: inline-block;
            transform: rotate(0deg);
            font-size: 12px; /* Adjust the font size to change the caret size */
        }

        .more-blogs.expanded .caret {
            transform: rotate(90deg);
        }

        @media screen and (max-width: 768px) {
        .blog-post {
            padding: 10px; /* Adjust spacing for smaller screens */
        }
        .blog-post img {
            max-width: 80%; /* Reduce image size for smaller screens */
        }
        .box-index {
        display: none; /* Hide the index on smaller screens */
        }
    }

    </style>
</body>
</html>

<script>
    function toggleMoreBlogs() {
        var subMenu = document.querySelector('.more-blogs .sub-menu');
        var parentItem = document.querySelector('.more-blogs');
        subMenu.classList.toggle('expanded');
        parentItem.classList.toggle('expanded');
    }
</script>
