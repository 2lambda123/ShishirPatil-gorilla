<!DOCTYPE html>
<html>
<head>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NRZJLJCSH6"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-NRZJLJCSH6');
    </script>


    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <title>Introduction to Gorilla LLM</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro">
    <link rel="stylesheet" href="assets/css/Highlight-Clean.css">
    <link rel="stylesheet" href="assets/css/styles.css">
    <link rel="stylesheet" href="assets/css/Team-Clean.css">
</head>

<body>
    <!-- Navigation Bar -->
    <div class="navbar" style="position: absolute; top: 0; right: 20px; padding: 10px; z-index: 100;font-size: 18px;">
        <a href="../index.html">Home </a>&nbsp;&nbsp;&nbsp;     
        <a href="../blog.html"> Blog</a>
    </div>

    <div class="highlight-clean-blog" style="padding-bottom: 10px;">
        <h1 class="text-center" style="padding-bottom: 10px;"> ü¶ç Gorilla: Large Language Model Connected with Massive APIs</h1>

        <!-- <div class="box-index">
            <h3>Blog 4: OpenFunctions</h3>
            <ul>
                <ul>
                        <li><a href="4_open_functions.html#how_to_use_open_functions">How to use OpenFunctions</a></li>
                        <li><a href="4_open_functions.html#benchmarking">OpenFunctions Benchmarking</a></li>
                        <li><a href="4_open_functions.html#data_composition">OpenFunctions Data Composition</a></li>
                        <li><a href="4_open_functions.html#function_vs_rest">Code Function Calling API vs. REST API</a></li>
                        <li><a href="4_open_functions.html#models">Models and Capabilities</a></li>
                        <li class="more-blogs">
                            <a href="javascript:void(0);" onclick="toggleMoreBlogs()">More Blogs <span class="caret">&#9654;</span></a>
                            <ul class="sub-menu">
                                <li><a href="1_gorilla_intro.html">Introduction to Gorilla LLM</a></li>
                                <li><a href="2_hallucination.html">Hallucination</a></li>
                                <li><a href="3_retreiver_aware_training.html">Retrieval Aware Training (RAT)</a></li>
                                <!-- Add more blog entries as needed -->
                            </ul>
                        </li>  
                </ul>
                <!-- Add more entries as needed -->
            </ul>
        </div> -->


        <div class="blog-container">
            <div class="blog-post">
                <h2 class="blog-title">Gorilla OpenFunctions</h2>
                <div class="author-date">
                    <p class="author"> Fanjia Yan </p>
                    <p class="author"> Adam Lee </p>
                    <p class="author"> <a href="https://tianjunz.github.io">Tianjun Zhang</a> </p>
                    <p class="author"> <a href="https://people.eecs.berkeley.edu/~shishirpatil/">Shishir G. Patil</a> </p>
                    <p class="author"> <a href="https://people.eecs.berkeley.edu/~istoica">Ion Stoica</a> </p>
                    <p class="author"> <a href="https://people.eecs.berkeley.edu/~jegonzal/">Joseph E. Gonzalez</a> </p>
                    <p class="date">Nov 13, 2023</p>
                </div>
                    <img src="../assets/img/blog_post_4_gorilla_open_function_calling.png" alt="Gorilla introductory image" style="width: 95%;">
                    <p width="80%" style="text-align:center; margin-left:10%; margin-right:10%; padding-bottom: -10px">
                        <i style="font-size: 0.9em;">
                            Gorilla OpenFunctions is a drop-in open-source alternative. Given a prompt and API, Gorilla returns the correctly formatted function call. 
                            With Apache 2.0 licensed models, you can integrate OpenFunctions into your applications directly! 
                        </i>
                    </p>

                <div class="preview">
                    <p>
                        OpenFunctions is designed to extend Large Language Model(LLM) Chat Completion feature to formulate executable APIs call given natural language instructions and API context. Imagine if LLM could fill in parameters for a variety of service ranging from Instagram and Doordash to tools like Google Calendar and Stripe. Even users who are less familiar with API calling procedure and programming could use the model to generate APIs call to desired function. Open Function is an LLM that we train using a curated set of API documentations and Question Answer pairs generated from the API documentations. We have continued to expand on the Gorilla Paradigm and sought to improve the quality and accuracy of valid function calling generation.

                    </p>
                    <p>
                        Quick Links:
                        <ul>
                            <li>Colab Notebook: <a href="https://colab.research.google.com/drive/16M5J2H9F8YQora_W2PDnp120slZH-Mqd?usp=sharing">OpenFunctions</a></li>
                            <li>Dataset: <a href="https://github.com/ShishirPatil/gorilla/tree/main/openfunctions">GitHub</a></li>
                            <li>Models on HuggingFace: <a href="https://huggingface.co/gorilla-llm/gorilla-openfunctions-v1">gorilla-llm/gorilla-openfunctions-v1</a></li>
                        </ul>
                    </p>
                </div>

                <!-- How to use OpenFunctions -->

                <h4 id="how_to_use_open_functions">How to use OpenFunctions</h4>
                <p style="text-align: center; margin-bottom: 0">
                    <img src="../assets/img/blog_post_4_new_api_page.png" alt="Gorilla Input and Output" width="65%">
                        <i style="font-size: 0.9em;">
                            OpenFunctions can write accurate API calls. This applies not just the popular python package and cloud CLI but also any callable functions with API documentations!
                        </i>
                </p>
                <div class="body">
                    <p>Using Gorilla OpenFunctions is straightforward:
                        <ol>
                        <li>Define Your Functions: Provide a JSON file containing descriptions of your custom functions. Each function should contains field: <code>name</code>, the name of the API, <code>api_call</code>, the way we should invoke this API, <code>description</code>, the functionality of the API, and lastly <code>parameters</code>, which is a list of parameters pretains to the API call. Below is an example of sufficent API documentation that can feed into Open Function.</li>
                        <pre><code>
    function_documentaion = {  
        "name" : "Order Food on Uber",
        "api_call": "uber.eat.order",
        "description": "Order food on uber eat given a list of items and the quantity of items respectively",
        "parameters": 
            [
                {
                    "name": "restaurants", 
                    "description": "The restaurants user wants to order from" 
                }, 
                {
                    "name": "items", 
                    "description": "A list of order user wants to order from restaurants"
                },
                {
                    "name": "quantities", 
                    "description": "A list of quantities corresponding to the items ordered"
                }
            ]
        }
                        </code></pre>
                        <li>Ask Your Question: Describe what you want as if talking to another person.</li>
                        <code>I want to order five burgers and six chicken wings from McDonlad.</code>
                        <li>Get Your Function Call: The model will return a Python function call based on your request.</li>
                        This opens up possibilities for developers and non-developers alike, allowing them to leverage complex functionalities without writing extensive code.</p>
                        <p>Input:</p>
                        <pre><code>
    get_gorilla_response(prompt="I want to order five burgers and six chicken wings from McDonlad.", 
                         functions=[function_documentaion])</code></pre>
                        <p>Output:</p>
                        <pre><code>
    uber.eat.order(restaurants="McDonald",item=["chicken wings", "burgers"], quantity=[6,5])</code></pre></ol></p>
                </div>

                <!-- OpenFunction BenchMarking  -->
                <h4 id="benchmarking">OpenFunctions Performance Benchmarking</h4>
                <div class="body">
                    <p>We are benchmarking our model against current state-of-art model GPT-4-0613 as well as  GPT-4 and GPT-3.5-turbo function calling features. Our testing dataset consists of 116 distinct query, API documentation pairs and are crafted by feeding few shot examples into GPT-3.5-turbo and asking the model to generate APIs from different domains including travel, finance, meeting scheduling.</p>
                        <img src="../assets/img/blog_post_4_OpenFunctions_Distribution.png" alt="Open functions types of data" width="85%" >
                            <i class="centered-text" style="font-size: 0.9em;" width="85%">
                                Suprisingly, we observe that GPT-4 and GPT-3.5 function calling perform better than the State of the Art GPT-4-Turbo model. Our OpenFunctions model is closely behind with tiny margin.
                            </i>
                        <br>
                    <p> To evalate the quality of the ouput, we perform side-by-side examination between the model output and gold answer. From the graph above, we can see that GPT-4 and GPT-3.5-Turbo performs function callings with a higher success rate around 95% than GPT-4 function callings. Our llama-based OpenFunction model is following GPT-4 function calling with a 86% success rate. Below is an example of GPT-4 fails to extract parameters correctly.</p>
                    <p> Below are two examples of GPT-4 generate unsatisfied results:</p>
                    <div class="container">
                        <div class="code-block">
                            <!-- Your first code section goes here -->
                            <pre>
                                <code>
"Query": "Determine the monthly mortgage payment for a loan
        amount of $200,000, an interest rate of <span style="color:#ff0000;">4%</span>, and a 
        loan term of 30 years.",
"GPT-4 output":
    "{"name": "financ.calculate_mortgage_payment",
    "arguments": "{"loan_amount": 200000,
                    "interest_rate": <span style="color:#ff0000;">4</span>,
                    "loan_term": 30}"
                    }",

"Gold answer": "finance.calculate_mortgage_payment(
                    loan_amount=200000, 
                    interest_rate=<span style="color:#0000FF;">0.04</span>, 
                    loan_term=30)"
                                </code>
                            </pre>
                        </div>
                        <div class="code-block">
                            <!-- Your second code section goes here -->
                            <pre>
                                <code>
"Query": "Order me <span style="color:#FF0000;">six</span> pack of potato chips and <span style="color:#FF0000;">eight</span> 
        pack of chocolate from target near Berkeley.",
"GPT-4 output":
        "{ "name": "target.get",
            "arguments": "{
                "loc": "Berkeley",
                "item": ["six pack of potato chips", 
                "eight pack of chocolate"],
                "quantity": <span style="color:#FF0000;">[1, 1]}</span>
                    }",
"Gold answer": "target.order(
                  loc=Berkeley,
                  item=["potato chips", "chocolate"]</span>, 
                  quantity=<span style="color:#0000FF;">[6,8]</span>)"

                                </code>
                            </pre>
                        </div>
                    </div>
                    <p>As we can see from the above mistakes that even using GPT-4 function calling isn't able to guarantee us on satisfactory result on analysis of function parameters. Here, we have a detailed breakdown of the percentage of success, failure of our testing data:</p>
                        <img src="../assets/img/blog_post_4_OpenFunctions_Mistake.png" alt="GPT-failure" width="85%" >
                        <i class="centered-text" style="font-size: 0.9em;" width="85%">
                            While the standard GPT model is able to produce definitive results, OpenAI's function calling model will ask follow up question if required parameters are not supplied, which results in a state of no result.
                        </i>
                        <br>
                    <p> When calling to OpenAI's function calling models, if required parameters are not supplied within instruction. This leads the function calling models to output "follow-up" questions requesting the required parameters which results in "incomplete" status as displayed in above graph. 
                        We treat "incomplete" execution as "success" during our accuracy calculation because the model recognize the missing parameters successfully. 
                        Our Open Function model as well as regular GPT-4, due to its chat complete nature, will fill up the required parameters with place holder or default value which allows undisturbed generation. </p>

                </div>
                <!-- OpenFunctions Data Composition -->

                <h4 id="data_composition"> OpenFunctions Data Composition</h4>
                <div class="body">
                    <p>
                        The dataset we trained our model on consists of 14189 API documentations 14189 question-answer pairs. The API documentations are collected from 3 sources: 
                        
                    </p>
                    <ul>
                        <li><strong>Python packages</strong>: The Python packages are collected from the official documentation of the packages. We intentionally chose packages that are clean and well-documented and those packages typically belong to scientific computing and machine learning domains.</li>
                        <li><strong>RapidAPI</strong>: The RapidAPI documents are collected from the API marketplace. Since RapidAPI typically makes requests to an API endpoint. We format the API documentation to have function <code>requests.get</code> with properties: <code>url</code>, <code>headers</code>, <code>params</code>. Completing this function will enable the user to call <code>requests.get</code> successfully to the API endpoint.</li>
                        <li><strong>Command Line Tool from various cloud provider</strong>: Lastly we relies on CLI documentation from AWS, Azure, and etc. We use those documentation to construct python-like function calling.</li>
                    </ul>
                    <p>
                        For each API documentation, we generate three distinct instruction and model answer as our training data. The instruction and model answer pairs are self-generated using few shots examples of correctly utilizing API documentations to extrapolate the function callings. We explicitly prompt the model to take advantage of features like complex value type and more parameters if the specific API has the feature. 
                    <div class="image-container">
                        <img src="../assets/img/blog_post_4_OpenFunctions_Data_Service.png" alt="Open functions types of data" width="55%" >
                        <img src="../assets/img/blog_post_4_OpenFunctions_Data_Detail.png" alt="Open functions types of service providers" width="45%" >
                        <br>
                    </div>
                        <i class="centered-text" style="font-size: 0.9em;" width="85%">
                            OpenFunctions's Data is collected through a variety of service and domain.
                        </i>
                    <p>    
                        
                    </p>

                </div>

                <h4 id="function_vs_rest"> Code Function Calling API vs. REST API</h4>
                <div class="body">
                    <p>
                        During the data collection process, we have observed that general API calling can be divided into 2 categories: 
                    </p>
                    <ul>
                        <li>Code Function Calling APIs </li>
                        <li>REST APIs</li>
                    </ul>
                    <p>    
                        First, the Code Function Calling APIs are typically seen in external python packages like Numpy, Sklearn. Those APIs are well-defined and easily formatted. In anther word, knowing the 'api_name' e.g. <code>numpy.sum()</code> and the 'arguments' specification, we are able to extrapolate an executable function API. Due to its stable format and fixed locality, it takes relatively few data to fine-tune the model. 
                    </p>
                    <p> 
                        On the other hand, the REST APIs also accounts for a significant portion of the APIs in the market. Those APIs are typically provided by third-party hosting and offer a variety of functionality ranging from financial service to weather forecasting. Often time, REST APIs contain three parameter metadata: <code>url</code>, <code>header</code>, and <code>params</code>. Url contains the API endpoints, header usually contains authentication information, and paramters contain information query to the API endpoint. Using <code>requests.get</code> we are able to properly query to the endpoint. However, REST APIs' parameters can exist in different locations. For example, the parameters can be embedded within the URL e.g. <code>gorilla.berkeley.edu/{param1}/{param2}</code>. Another way to represent parameters embedding can be <code>gorilla.berkeley.edu/?query=param1</code>. Different ways of calling REST API make it difficult for our model to handle complex REST API call. As a result, we have explored different sources of REST APIs such as RapidAPI, Postman API to diversify our API Database and generate more accuracte REST API.

                    </p>
                </div>

                <!-- Parallel Functions  -->
                <h4 id="models">Models and Capabilities!</h4>

                <div class="body">
                    <p>We are happy to release two models: <code>gorilla-openfunctions-v0</code> and  <code>gorilla-openfunctions-v1</code>. 
                    <code>gorilla-openfunctions-v0</code> is a 13B parameter model trained on top of the 7B LLaMA-v2-chat instruction-tuned model. 
                    It takes-in the users prompt along with a SINGLE API call and returns the function with the right arguments.
                    <code>gorilla-openfunctions-v0</code> is a 7B paramter model trained on top of the 7B LLaMA-v2 pre-trained model. <code>gorilla-openfunctions-v0</code> 
                    is our advanced model that takes-in the users prompt along with MULTIPLE API calls and returns the function with the right arguments. 
                    It also supports paralle functions! <code>gorilla-openfunctions-v1</code> is in early pre-view and you can expect it to get much better over the next few days! 
                    All of the results in the blog are generated using <code>gorilla-openfunctions-v0</code>.
                    </p>

                    <hr class="post-separator">

                    <p>
                        We hope you enjoyed this blog post. We would love to hear from you on <a href="https://discord.gg/3apqwwME">Discord</a>, Twitter (#GorillaLLM), and <a href="https://github.com/ShishirPatil/gorilla/">GitHub</a>.<br> 
                    </p>
                    <p id="gorilla-bibtex">
                        If you would like to cite Gorilla:<br>
                        @inproceedings{patil2023gorilla,
                        &nbsp; 	title={Gorilla: Large Language Model Connected with Massive APIs},
                        &nbsp; 	author={Shishir G. Patil and Tianjun Zhang and Xin Wang and Joseph E. Gonzalez},
                        &nbsp; 	year={2023},
                        &nbsp;	journal={arXiv preprint arXiv:2305.15334}
                    }</p>
                </div>
            </div>
        </div>
    </div>

    <style>
        body {
            font-family: 'Source Sans Pro', sans-serif;
            margin: 0;
            padding: 0;
            background: white;
            justify-content: center;
            align-items: center;
        }
        .centered-text {
            text-align: center;
            display: block; /* Ensure the <i> element takes up the full width available */
            margin: 0 auto; /* Center the element horizontally */
        }
        .container {
            display: flex;
        }

        .code-block {
            width: 65%;
            padding: 10px;
            flex: 1; /* This makes each code block take equal width */
        }
        .image-container {
            display: flex;
            justify-content: center;
        }
        .image-container img {
            margin: 10px;
        }
        .blog-container {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }
        .blog-post {
            margin: 20px;
            padding: 20px;
            max-width: 1000px; 
            justify-content: center;
        }
        .blog-post img {
            display: block;
            margin: 0 auto;
        }
        .blog-title{
            color: #055ada;
            text-align: center;
        }

        .author-date {
                display: flex;
                margin-bottom: 0px;
                justify-content: center; 
        }
        .author {
                font-size: 16px;
                color: #1E90FF;
                margin-right: 20px;
        }

        .date {
            font-size: 16px;
            color: #7e8790;
        }

        .preview {
            text-align: justify; 
            text-justify: inter-word; 
        }

        .highlight-clean-blog {
            color: #313437;
            background-color: #fff;
            padding: 50px 0;
        }

        .box-index {
        position: fixed;
        top: 50%; 
        left: 0px; 
        transform: translateY(-50%);
        background-color: #f9f9f9;
        padding: 20px;
        border-radius: 8px;
        box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        max-width: 150px;
        }

        .box-index h3 {
        font-size: 1.2em;
        margin-bottom: 10px;
        }

        .box-index ul {
        list-style-type: disc;
        padding: 0;
        }

        .box-index ul li {
        margin-bottom: 10px;
        }

        .box-index ul li a {
        text-decoration: none;
        color: #333;
        }

        .box-index ul li a:hover {
        color: #1E90FF;
        }

        .more-blogs .sub-menu {
            display: none;
        }

        .more-blogs .sub-menu.expanded {
            display: block;
            max-height: 200px; /* Adjust the max height as needed */
            overflow-y: auto;
        }

        .more-blogs .sub-menu li {
            padding: 10px;
            border-bottom: 1px solid #ccc;
        }

        .more-blogs .sub-menu li:last-child {
            border-bottom: none;
        }

        .more-blogs .caret {
            transition: transform 0.3s ease-in-out;
            display: inline-block;
            transform: rotate(0deg);
            font-size: 12px; /* Adjust the font size to change the caret size */
        }

        .more-blogs.expanded .caret {
            transform: rotate(90deg);
        }

        @media screen and (max-width: 768px) {
        .blog-post {
            padding: 10px; /* Adjust spacing for smaller screens */
        }
        .blog-post img {
            max-width: 80%; /* Reduce image size for smaller screens */
        }
        .box-index {
        display: none; /* Hide the index on smaller screens */
        }
    }

    </style>
</body>
</html>

<script>
    function toggleMoreBlogs() {
        var subMenu = document.querySelector('.more-blogs .sub-menu');
        var parentItem = document.querySelector('.more-blogs');
        subMenu.classList.toggle('expanded');
        parentItem.classList.toggle('expanded');
    }
</script>
